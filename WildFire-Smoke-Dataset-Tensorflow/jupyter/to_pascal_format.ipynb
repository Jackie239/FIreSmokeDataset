{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2211f0e-7cf5-4e78-9db5-261253403abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "from xmlMaker import init_xml\n",
    "from xmlMaker import add_object\n",
    "from xmlMaker import prettyXml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99ef47-d2ea-4106-94f5-d06e8cc6cca3",
   "metadata": {},
   "source": [
    "# make XML file"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06d7cf8a-fbee-46b0-aa8d-2c6e1e75805e",
   "metadata": {},
   "source": [
    "folder structure:\n",
    "\n",
    "|---WildFire-Smoke-Dataset-Tensorflow\n",
    "    |---valid(_annotations.scv, *.jpg)\n",
    "    |---train(_annotations.scv, *.jpg)\n",
    "    |---test(_annotations.scv, *.jpg)\n",
    "    |---Tools(*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98c1148a-c2f9-4c4d-90d7-44da8d268ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6465e38faf4c7d9f4f9747ed37ffd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5eb0b2ab6c4f338ac528810d4e603d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04250218986c489ea5e960d98339a17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8d12affc8a48d2b21097adc450330b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmlFolderPath = os.path.join('../', 'Annotations/')\n",
    "if not os.path.exists(xmlFolderPath):\n",
    "    os.mkdir(xmlFolderPath)\n",
    "\n",
    "folderList = ['valid', 'train', 'test']\n",
    "for folderName in tqdm(folderList):\n",
    "    folderPath = '../{}/'.format(folderName)\n",
    "    annotationsPath = os.path.join(folderPath,'_annotations.csv')\n",
    "    with open(annotationsPath, 'r') as f:\n",
    "        csvRead = [x.strip() for x in f.readlines()]\n",
    "\n",
    "    csvRead = csvRead[1:]\n",
    "    for line in tqdm(csvRead):\n",
    "        imageName = line.split('.jpg,')[0]\n",
    "        xmlPath = os.path.join(xmlFolderPath, '{}.xml'.format(imageName))\n",
    "        bbox = line.split('smoke,')[-1]\n",
    "        bbox = [int(x) for x in bbox.split(',')]\n",
    "\n",
    "        # init xml\n",
    "        if not os.path.exists(xmlPath):\n",
    "            init_xml(xmlPath, 'WildFire-Smoke-Dataset-Tensorflow', imageName, \n",
    "                    'WildFire-Smoke-Dataset-Tensorflow_smoke_detection', \n",
    "                    imageWidth=640, imageHeight=480)\n",
    "\n",
    "        # add object info\n",
    "        tree = ET.parse(xmlPath)\n",
    "        add_object(tree, bbox, 'smoke')\n",
    "        # reshape xml\n",
    "        root = tree.getroot()\n",
    "        prettyXml(root, '\\t', '\\n')\n",
    "        # save\n",
    "        tree.write(xmlPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b6194-6d5a-47b1-b3bc-70dc5c472bb9",
   "metadata": {},
   "source": [
    "# generate ImageSets and JPEGImages floders\n",
    "\n",
    "## make JPEGImages\n",
    "\n",
    "copy images into JPEGImages foldes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbb90d37-6287-4339-bc94-3411166e321c",
   "metadata": {},
   "source": [
    "folder structure:\n",
    "\n",
    "|---WildFire-Smoke-Dataset-Tensorflow\n",
    "    |---Annotations\n",
    "    |---valid(_annotations.scv, *.jpg)\n",
    "    |---train(_annotations.scv, *.jpg)\n",
    "    |---test(_annotations.scv, *.jpg)\n",
    "    |---Tools(*.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108eae1-3568-409d-b06c-5cfcb7637360",
   "metadata": {},
   "source": [
    "## make ImageSets\n",
    "\n",
    "loading all image names, distribute them into trainset(70%) and testset(3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "daf936a9-95d1-4314-a4a9-e7ea7575d19f",
   "metadata": {},
   "source": [
    "folder structure:\n",
    "\n",
    "|---WildFire-Smoke-Dataset-Tensorflow\n",
    "    |---Annotations(*.xml)\n",
    "    |---JPEGImages(*.jpg)\n",
    "    |---valid(_annotations.scv, *.jpg)\n",
    "    |---train(_annotations.scv, *.jpg)\n",
    "    |---test(_annotations.scv, *.jpg)\n",
    "    |---Tools(*.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c41fd4-f21f-4df6-882e-a1f053060b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationsPath = '../Annotations/'\n",
    "\n",
    "allImage = [x.split('.xml')[0] for x in os.listdir(annotationsPath)]\n",
    "\n",
    "imageSetsPath = '../ImageSets/Main/'\n",
    "# make ImageSetsPath folder\n",
    "if not os.path.exists(imageSetsPath):\n",
    "    os.makedirs(imageSetsPath)\n",
    "    \n",
    "allImage = np.array(allImage)\n",
    "\n",
    "testSize = int(len(allImage) * 0.3)\n",
    "# shuffle\n",
    "np.random.shuffle(allImage)\n",
    "# sample\n",
    "testIndex = random.sample(range(len(allImage)), testSize)\n",
    "testList = allImage[np.array(testIndex)]\n",
    "trainList = [item for item in allImage if item not in testList]\n",
    "# save\n",
    "trainTxtPath = os.path.join(imageSetsPath, 'trainval.txt')\n",
    "testTxtPath = os.path.join(imageSetsPath, 'test.txt')\n",
    "\n",
    "with open(trainTxtPath, 'w') as f:\n",
    "    for image in trainList:\n",
    "        f.write('{}\\n'.format(image))\n",
    "\n",
    "with open(testTxtPath, 'w') as f:\n",
    "    for image in testList:\n",
    "        f.write('{}\\n'.format(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.2.1",
   "language": "python",
   "name": "jupyterkernelfile_pytorch2.2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
